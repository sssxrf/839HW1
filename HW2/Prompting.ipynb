{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311451f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Which element has the chemical symbol 'W'?\n",
      "Model: gpt-4o-mini\n",
      "Samples per temperature: 7\n",
      "\n",
      "--- Temperature 0.20 ---\n",
      "Majority: the chemical symbol w stands for tungsten  (3/7 votes)\n",
      "\n",
      "--- Temperature 0.50 ---\n",
      "Majority: the chemical symbol w stands for tungsten  (3/7 votes)\n",
      "\n",
      "--- Temperature 0.80 ---\n",
      "Majority: the element with the chemical symbol w is tungsten  (4/7 votes)\n",
      "\n",
      "--- Temperature 1.20 ---\n",
      "Majority: the element with the chemical symbol w is tungsten  (4/7 votes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import collections\n",
    "import re\n",
    "from typing import List, Dict\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---------- Config ----------\n",
    "MODEL = \"gpt-4o-mini\"         # pick any chat model you have access to\n",
    "QUESTION = \"Which element has the chemical symbol 'W'?\"\n",
    "TEMPS = [0.2, 0.5, 0.8, 1.2]  # temperatures to test\n",
    "SAMPLES_PER_TEMP = 7          # how many samples to draw at each temperature\n",
    "MAX_TOKENS = 64               # response length cap\n",
    "os.environ[\"OPENAI_API_KEY\"] =  \"set key hide from repo\"  # set your OpenAI API key\n",
    "# ----------------------------\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    \"\"\"Light normalization + simple synonym mapping example.\"\"\"\n",
    "    t = text.strip().lower()\n",
    "    t = re.sub(r\"[^a-z \\-]\", \"\", t)\n",
    "    # Treat 'wolfram' as synonym for 'tungsten'\n",
    "    if \"wolfram\" in t:\n",
    "        return \"tungsten\"\n",
    "    return t\n",
    "\n",
    "def one_sample(question: str, temperature: float, seed: int | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Get a single sampled answer at a given temperature.\n",
    "    Note: 'seed' is optional; many Chat Completions models accept it.\n",
    "    If unsupported for your model, remove the 'seed' argument below.\n",
    "    \"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": question}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        n=1,\n",
    "        seed=seed,  # comment out if your model rejects this param\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "def sample_many(question: str, temperature: float, k: int) -> List[str]:\n",
    "    \"\"\"Draw k independent samples at a fixed temperature.\"\"\"\n",
    "    answers = []\n",
    "    for i in range(k):\n",
    "        txt = one_sample(question, temperature, seed=i)  # vary seed for reproducibility\n",
    "        answers.append(txt)\n",
    "    return answers\n",
    "\n",
    "def majority_vote(answers: List[str]) -> Dict:\n",
    "    \"\"\"Return raw answers, normalized votes, and the winner.\"\"\"\n",
    "    normed = [normalize(a) for a in answers]\n",
    "    tally = collections.Counter(normed)\n",
    "    winner, count = tally.most_common(1)[0]\n",
    "    return {\n",
    "        \"raw\": answers,\n",
    "        \"normalized\": normed,\n",
    "        \"tally\": tally,\n",
    "        \"winner\": winner,\n",
    "        \"votes\": count,\n",
    "    }\n",
    "\n",
    "def run(question: str, temps: List[float], k: int):\n",
    "    print(f\"\\nQuestion: {question}\\nModel: {MODEL}\\nSamples per temperature: {k}\\n\")\n",
    "    for T in temps:\n",
    "        answers = sample_many(question, T, k)\n",
    "        result = majority_vote(answers)\n",
    "        print(f\"--- Temperature {T:.2f} ---\")\n",
    "        print(f\"Majority: {result['winner']}  ({result['votes']}/{k} votes)\")\n",
    "        # (optional) uncomment to see all raw answers:\n",
    "        # for i, a in enumerate(result[\"raw\"], 1):\n",
    "        #     print(f\"{i}. {a}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run(QUESTION, TEMPS, SAMPLES_PER_TEMP)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
